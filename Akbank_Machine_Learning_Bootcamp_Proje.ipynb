{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Merhabalar, bu dosyada Akbank Makine öğrenmesi için hazırlanan projeye dair kodlar mevcuttur. Proje Sınıflandırma üzerine hazırlanmıştır. İyi okumalar."
      ],
      "metadata": {
        "id": "MUn-m7SlpFWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Öncelikle excel dosyasını okumak için Google Drive'a eklediğimiz dosyayı bulmak için Drive'a bağlanıyoruz. (Bu şekilde yapmadan dosyayı okuyamadım)"
      ],
      "metadata": {
        "id": "OFAzyHJH9G_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To read/write data from Google Drive:\n",
        "#Reference: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveAå\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# #When done,\n",
        "# drive.flush_and_unmount()\n",
        "# print('All changes made in this colab session should now be visible in Drive.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8syiKKHbsTNp",
        "outputId": "9387938d-a9ca-405a-9e6c-30bbb3b49287"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drive dosyası içinde ki dosyayı okuduktan sonra excel dosyasını inceliyoruz. Kullandığımız veri seti Meksika, Peru ve Kolombiya için obezite levellerininin bazı sorularla araştırılmasına dayanıyor. Dosyabın içeriği şu şekilde:\n",
        "\n",
        "Cinsiyet: Gender, Yaş: Age, Boy: Height, Kilo: Weight,\n",
        "family_history_with_overweight: Aileden biri obezite mi?,\n",
        "FAVC : Yüksek kalorili yiyecekleri sıklıkla yer misin?,\n",
        "FCVC : Sebze tüketiyor musunuz?,\n",
        "NCP : Bir günde ka öğün besleniyorsun?,\n",
        "CAEC : Öğünler arasında atıştarmalık yiyor musun?,\n",
        "SMOKE : Sigara kullanıyor musun?,\n",
        "CH2O: Ne kadar su tüketiyorsun?,\n",
        "SCC: Kalori takibi yapıyor musun?\n"
      ],
      "metadata": {
        "id": "bBavAMLbXeF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "veri_seti = pd.read_excel('/content/drive/My Drive/Akbank Bootcamp/dataset.xlsx')\n",
        "\n",
        "# Veri setinin ilk birkaç satırını görüntüle\n",
        "print(\"Veri setinin ilk birkaç satırı:\")\n",
        "print(veri_seti.head())\n",
        "\n",
        "# Sütun isimlerini kontrol et\n",
        "print(\"\\nSütun isimleri:\")\n",
        "print(veri_seti.columns)\n",
        "\n",
        "# Veri tiplerini göster\n",
        "print(\"\\nVeri tipleri:\")\n",
        "print(veri_seti.dtypes)\n",
        "\n",
        "# İstatistiksel özet\n",
        "print(\"\\nİstatistiksel özet:\")\n",
        "print(veri_seti.describe())\n",
        "\n",
        "# Kategorik sütunların frekanslarını göster\n",
        "print(\"\\nKategorik sütunların frekansları:\")\n",
        "print(veri_seti['Gender'].value_counts())\n"
      ],
      "metadata": {
        "id": "e-dSKAK0uTjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veri setini yukarıda ki kodlarla inceleyerek hangi sütunlar var, hangi veriler hangi tipe ait, kaç veri var, min ve max değerleri neler, kategorik değerlerin frekanslarını da görebiliyoruz."
      ],
      "metadata": {
        "id": "HsbbDoaO9lJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Histogram oluşturma\n",
        "plt.hist(veri_seti['Age'], bins=10, color='skyblue', edgecolor='black')\n",
        "\n",
        "# Grafik başlığı ve eksen etiketleri\n",
        "plt.title('Yaşlara göre dağılımı')\n",
        "plt.xlabel('Değer Aralığı')\n",
        "plt.ylabel('Frekans')\n",
        "\n",
        "# Histogramı gösterme\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NCWv35C3ulTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histogram sayesinde soruları cevaplayan kişilerin yaş aralıklarını görebiliyoruz"
      ],
      "metadata": {
        "id": "p1wenB4_v57c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Veri setindeki kategorik sütunun frekanslarını hesapla\n",
        "kategori_frekanlari = veri_seti['NObeyesdad'].value_counts()\n",
        "\n",
        "# Pasta grafiği oluşturma\n",
        "plt.figure(figsize=(8, 8))  # Grafiğin boyutunu ayarla\n",
        "plt.pie(kategori_frekanlari, labels=kategori_frekanlari.index, autopct='%1.1f%%', startangle=140)\n",
        "\n",
        "# Grafiğin başlığını ekle\n",
        "plt.title('Obezite seviyelerinin dağılımı')\n",
        "\n",
        "# Pasta grafiğini gösterme\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VrCEGeTgwiCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pasta grafiği sayesinde hangi seviyelerde ne kadar yüzdelikte olduğunu da görebiliyoruz."
      ],
      "metadata": {
        "id": "kT8n8eF__GDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Kategorik sütunları seçin\n",
        "kategorik_sutunlar = ['Gender', 'CALC', 'FAVC', 'SCC', 'SMOKE', 'family_history_with_overweight', 'CAEC', 'MTRANS', 'NObeyesdad']  # Kategorik sütun isimlerini buraya girin\n",
        "\n",
        "# Label encoding işlemi\n",
        "label_encoder = LabelEncoder()\n",
        "for sutun in kategorik_sutunlar:\n",
        "    veri_seti[sutun + '_encoded'] = label_encoder.fit_transform(veri_seti[sutun])\n",
        "\n",
        "# Label encoding uygulanan veri setini göster\n",
        "print(veri_seti.head())\n"
      ],
      "metadata": {
        "id": "esYLsyXMw29g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kategorik verileri kodlanmış halde kullanmalıyız ki modellerimiz de herhangi bir sorunla karşılaşmayalım. Bu yüzden LabelEncoder kullandık. 0 dan başlayarak bulduğu kategorik verileri kodlandırıyoruz."
      ],
      "metadata": {
        "id": "QwyCd2iX_TO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encoding uygulanan veri setini \"label_encoded_veri_seti.xlsx\" olarak kaydet\n",
        "veri_seti.to_excel('/content/drive/My Drive/Akbank Bootcamp/label_encoded_veri_seti.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "HFmXRFTV0yyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bunu ayrı bir excel dosyası olarak kullanmak istedim ki orjinal hali bozulmasın. kodlanmış hallerini ayrı bir sütun olarak aldığı için ufak düzenlemeler yaptım.\n"
      ],
      "metadata": {
        "id": "TwqDuGMiwcGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Label encoding işleminden geçmiş bir veri seti yükleyin\n",
        "label_encoded_veri_seti = pd.read_excel('/content/drive/My Drive/Akbank Bootcamp/label_encoded_veri_seti.xlsx')\n",
        "\n",
        "# Bağımsız değişkenler (X) ve bağımlı değişken (y)\n",
        "X = label_encoded_veri_seti.drop(columns=['NObeyesdad_encoded'])  # Bağımsız değişkenler\n",
        "y = label_encoded_veri_seti['NObeyesdad_encoded']  # Bağımlı değişken\n"
      ],
      "metadata": {
        "id": "vNR-twX_14GX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drive dosyasına attığımız yeni dosyayı okuyoruz ve bu kısımdan sonra artık test ve eğitim setlerimizi oluşturmaya başlamış olduk. Model değerlendirmesi için sınıflandırmayı esas alarak devam ediyoruz."
      ],
      "metadata": {
        "id": "3uHCtWwe_1dv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hangi modelin daha iyi olduğuna karar vermek için birkaç model belirledim. Bunlardan ilki K-Nearest Neighbors (k-NN), ikincisi Naive Bayes ve sonuncusu Decision Trees. modelleri test ettikten sonra elde ettiğimiz sonuçlar şu şekilde\n",
        "\n",
        "K-Nearest Neighbors (k-NN): Model Accuracy: 0.862776025236593\n",
        "\n",
        "Naive Bayes: Naive Bayes Model Accuracy: 0.6056782334384858\n",
        "\n",
        "Decision Trees: Decision Trees Model Accuracy: 0.917981072555205"
      ],
      "metadata": {
        "id": "BmJBwKVPAPgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hangi modelin daha iyi olduğuna kara vermek için crossvalidation yapmamız gerekli, üç model içinde sonuçlar şu şekilde:\n",
        "\n",
        "K-Nearest Neighnors: Cross-Validation Scores: [0.86148649 0.84797297 0.8440678  0.84745763 0.82033898]\n",
        "Mean CV Score: 0.8442647732478242\n",
        "\n",
        "Naive Bayes: Cross-Validation Scores: [0.64527027 0.59459459 0.54915254 0.59322034 0.59322034]\n",
        "Mean CV Score: 0.5950916170407696\n",
        "\n",
        "Decision Trees: Cross-Validation Scores: [0.91891892 0.92567568 0.93898305 0.93559322 0.89830508]\n",
        "Mean CV Score: 0.9234951901053596\n"
      ],
      "metadata": {
        "id": "sBekxCSiBQO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En iyi sonuçlar Decision Trees modeli ile olduğu için bundan sonra ki adımda decision trees için gerekli kodlara yer verdim."
      ],
      "metadata": {
        "id": "YLaiIMiqB1IX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Decision Trees modelinin oluşturulması\n",
        "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Modelin eğitilmesi\n",
        "decision_tree_model.fit(X_train, y_train)\n",
        "\n",
        "# Test veri kümesi üzerinde tahmin yapılması\n",
        "y_pred = decision_tree_model.predict(X_test)\n",
        "\n",
        "# Modelin performansının değerlendirilmesi\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Decision Trees Model Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkm2UoQP5yeL",
        "outputId": "0174bfcb-78b0-4161-df49-4cf22f210c7d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Trees Model Accuracy: 0.917981072555205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Decision Trees modelinin oluşturulması\n",
        "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Çapraz doğrulama yaparak modelin performansının değerlendirilmesi\n",
        "cv_scores = cross_val_score(decision_tree_model, X_train, y_train, cv=5)  # 5 katlı çapraz doğrulama\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean CV Score:\", cv_scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2zs7zIY6ND9",
        "outputId": "f544cc01-4a25-4fc7-869b-4b078a2fa808"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.91891892 0.92567568 0.93898305 0.93559322 0.89830508]\n",
            "Mean CV Score: 0.9234951901053596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bir sonraki adımd hiperparametre testi yapıyoruz. bu şekilde en iyi parametreleri neler olduğunu, modelin ne kadar iyi öğrendiğini görmüş olucaz. Grid Search yöntemi kullanarak modelimizi test ettik."
      ],
      "metadata": {
        "id": "TOXDIGnO6n92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Karar Ağaçları modeli için optimize edilecek hiperparametre aralıklarını belirleyin\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],  # Karar kriteri\n",
        "    'max_depth': [None, 5, 10, 15, 20],  # Ağacın maksimum derinliği\n",
        "    'min_samples_split': [2, 5, 10],  # Bir iç düğümün bölünmesi için gereken minimum örnek sayısı\n",
        "    'min_samples_leaf': [1, 2, 4]  # Bir yaprak düğümünde gereken minimum örnek sayısı\n",
        "}\n",
        "\n",
        "# Grid Search Cross-Validation\n",
        "grid_search = GridSearchCV(decision_tree_model, param_grid, cv=5)\n",
        "\n",
        "# Grid Search'i eğitin\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# En iyi parametreleri ve en iyi skoru yazdırın\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYnLWpWR7D1Z",
        "outputId": "be09c81b-4057-4d3c-bf5a-911b62c964fc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
            "Best Score: 0.9451557489693083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 'criterion' parametresi, karar ağacının nasıl bölüneceğini belirler. 'entropy', bir sistemdeki düzensizliği veya belirsizliği ölçmek için kullanılır. Gini olsaydı ne kadar benzer (saflık) diye bakıcaktık.\n",
        " 'max_depth', maksimum sınırı gösterir none olduğu için sınırsız.\n",
        " 'min_samples_leaf' 1 olması her yaprak düğümde en az bir tane örnek olması gerektiğini gösterir. yaprak düğüm son düğüm olduğu için bitişlerde bir düğüme ihtiyac duyuyoruz.\n",
        " 'min_samples_split' 5 olması her iç düğümde en az 5 örnek olması gerektiğni gösterir."
      ],
      "metadata": {
        "id": "2LQTpQzPTBLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# En iyi parametrelerle bir Karar Ağaçları modeli oluşturun\n",
        "best_decision_tree_model = DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=5, min_samples_leaf=1)\n",
        "\n",
        "# Modeli eğitin\n",
        "best_decision_tree_model.fit(X_train, y_train)\n",
        "\n",
        "# Test veri kümesi üzerinde tahmin yapın\n",
        "y_pred = best_decision_tree_model.predict(X_test)\n",
        "\n",
        "# Karışıklık matrisini oluşturun\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Doğruluk (Accuracy) hesaplayın\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Kesinlik (Precision) hesaplayın\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "# Duyarlılık (Recall) hesaplayın\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "# F1 puanı (F1 score) hesaplayın\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIOvP0y87bCp",
        "outputId": "537ae414-e5cb-4612-fa89-b1da649e03a0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[84  2  0  0  0  0  0]\n",
            " [ 7 75  0  0  0 11  0]\n",
            " [ 0  0 98  3  0  0  1]\n",
            " [ 0  0  6 82  0  0  0]\n",
            " [ 0  0  1  0 97  0  0]\n",
            " [ 0  1  0  0  0 85  2]\n",
            " [ 0  0  0  0  0  5 74]]\n",
            "Accuracy: 0.9384858044164038\n",
            "Precision: 0.9414562993965664\n",
            "Recall: 0.9384858044164038\n",
            "F1 Score: 0.9381819155755969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "hiper paramatere optimizasyonu ile elde ettiğimiz parametreleri kullanarak modelimizin doğruluğunu, F1 skorunu vs değerlendiriyoruz. Bunun için confusion matrix kullandık. bu matrix gerçek ve tahmin edilen sınıflar arasındaki karşılaştırmaları gösterir.\n",
        "\n",
        "Accuracy yani doğruluk değerlerin toplama oranla ne kadarının dopru olduğunu gösterir.\n",
        "\n",
        "Precision yani kesinlik positive olan değerlerimizin ne kadarının gerçekten true positive olduğunu gösterir.\n",
        "\n",
        "Recall yani duyarlılık positive olduğunu düşündüğümüz değerlerin ne kadarının gerçekten positive olduğunu gösterir. Recall tahmin etmeye dayanır.\n",
        "\n",
        "F1 skor Precision ve Recall arasında ki bağlantıyı dengeyi gösterir.\n",
        "\n",
        "Bu değerlerin yüksek çıkması modelin değerlendirmesi bakımından iyi öğrendiğini gösterir."
      ],
      "metadata": {
        "id": "-aiZLNqvWSf_"
      }
    }
  ]
}